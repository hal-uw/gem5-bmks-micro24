#!/bin/bash

# BFS
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_bfs configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/bfs/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c bin/bfs --options="multigpu_benchmarks/rodinia/bfs/graph65536.txt 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee bfs_large_cpcoh.log  &

# BACKPROP
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_backprop configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/backprop/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c bin/backprop --options="65536 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee backprop_large_cpcoh.log  &

# GAUSSIAN
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_gaussian configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/gaussian/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c gaussian --options="-f multigpu_benchmarks/rodinia/gaussian/matrix256.txt 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee gaussian_large_cpcoh.log  &

# HOTSPOT
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_hotspot configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/hotspot/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c hotspot --options="512 2 20 multigpu_benchmarks/rodinia/hotspot/temp_512 multigpu_benchmarks/rodinia/hotspot/power_512 multigpu_benchmarks/rodinia/hotspot/output.out 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee hotspot_large_cpcoh.log  &

# HOTSPOT3D
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_hotspot3D configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/hotspot3D/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c 3D --options="512 8 100 multigpu_benchmarks/rodinia/hotspot3D/power_512x8 multigpu_benchmarks/rodinia/hotspot/temp_512x8 multigpu_benchmarks/rodinia/hotspot/output.out" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee hotspot3D_large_cpcoh.log  &

# PATHFINDER
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_pathfinder configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/pathfinder/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c pathfinder --options="100000 100 20 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee pathfinder_large_cpcoh.log  &

# STREAM CLUSTER
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_streamcluster configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/streamcluster/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c sc_gpu --options="10 20 256 65536 65536 1000 none output.txt 1" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee streamcluster_large_cpcoh.log  &

# SRAD v2
docker run --rm --volume $(pwd):$(pwd) -w $(pwd) cpcoh build/GCN3_X86/gem5.opt --debug-flags=GlobalScheduler,CPCoh,GPUDisp --debug-file=run.log --outdir=results_cpcoh_large_srad_v2 configs/example/apu_se.py -n80 -u60 --cu-per-sa=60 --num-gpu-complex=1 --reg-alloc-policy=dynamic --barriers-per-cu=16 --num-tccs=8 --bw-scalor=8 --tcc-size=8192kB --tcc-assoc=32 --num-dirs=64 --mem-size=16GB --mem-type=HBM_1000_4H_1x64 --vreg-file-size=16384 --sreg-file-size=800 --num-hw-queues=256 --num-gpus=4 --gs-policy=GSP_RRCS --benchmark-root=multigpu_benchmarks/rodinia/srad/srad_v2/ --coal-tokens=160 --gpu-clock=1801MHz --ruby-clock=1000MHz --TCC_latency=121 --vrf_lm_bus_latency=6 --mem-req-latency=69 --mem-resp-latency=69 --TCP_latency=16 --gs-num-sched-gpu=2 -c srad --options="2048 2048 0 127 0 127 0.5 2 1 0" --max-coalesces-per-cycle=10 --sqc-size=16kB |& tee srad_v2_large_cpcoh.log  &